<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gesture Recognition System</title>
    <style>
        body {
            font-family: 'Times New Roman', serif;
            background-color: #f3f3f3; /* Choose any plain background color */
            margin: 0;
            padding: 0;
            color: #333;
        }

        h1 {
            font-family: 'Bookman Old Style', serif;
            color: #000; /* Black */
            text-align: center;
        }

        p {
            color: #444;
        }

        ol {
            list-style-type: none;
            padding: 0;
        }

        li {
            margin-bottom: 20px;
        }

        strong {
            color: #000; /* Black */
        }

        .button {
            display: inline-block;
            padding: 10px 20px;
            font-size: 16px;
            text-align: center;
            text-decoration: none;
            background-color: #000; /* Black */
            color: #fff;
            border-radius: 5px;
            transition: background-color 0.3s ease;
        }

        .button:hover {
            background-color: #333; /* Darker shade on hover */
        }
    </style>
</head>
<body>
    <h1>Gesture Recognition System</h1>
    <p>The following steps outline the implementation of static hand gesture recognition using PyTorch and CNNs:</p>

    <ol>
        <li><strong>Data Collection:</strong>
            <p>Collect a dataset of hand gesture images with 600 images for training and 300 images for validation, separated into 6 classes.</p>
        </li>

        <li><strong>Data Transformation:</strong>
            <p>Apply image resizing, grayscale conversion, and normalization transformations to enhance the dataset.</p>
        </li>

        <li><strong>Model Architecture:</strong>
            <p>Utilize a CNN architecture, specifically ResNet-18, for feature extraction and classification.</p>
        </li>

        <li><strong>Transfer Learning:</strong>
            <p>Fine-tune the pre-trained ResNet-18 model for hand gesture recognition.</p>
        </li>

        <li><strong>Training:</strong>
            <p>Train the model using backpropagation and stochastic gradient descent with tuned hyperparameters.</p>
        </li>

        <li><strong>Validation:</strong>
            <p>Validate the model using the validation set to fine-tune hyperparameters and prevent overfitting.</p>
        </li>

        <li><strong>Testing:</strong>
            <p>Test the model on live webcam input, capturing frames, applying transformations, and making predictions.</p>
        </li>
    </ol>

    <p>The confusion matrix summarizes the classification results with 6 classes:</p>
    <ul>
        <li>True Positives: 45 instances each for 'next' and 'previous' classes.</li>
        <li>True Positives: 50 instances each for 'pause', 'play', 'volume_down', and 'volume_up' classes.</li>
        <li>False Negatives: 5 instances of 'next' misclassified as 'volume_up'.</li>
        <li>False Negatives: 5 instances of 'previous' misclassified as 'volume_down' and 'next'.</li>
    </ul>

    <a href="gesture_code.html" class="button">View Code</a>
</body>
</html>
